{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahsaniqbal/CharacterLevelLM/blob/master/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8okPG7CAHMpA",
        "colab_type": "code",
        "outputId": "b378f57f-621a-40c6-f1b6-da97a1cb101f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'MachineLearning/CharLM/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjj75QW_aABV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "if not os.path.exists(base_dir):\n",
        "  os.makedirs(base_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuCph_ZtVxhx",
        "colab_type": "code",
        "outputId": "cbe8fe89-53e7-4533-e21d-db1cca0df7be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "!rm -r CharacterLevelLM\n",
        "!git clone https://github.com/ahsaniqbal/CharacterLevelLM\n",
        "import torch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CharacterLevelLM'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 63 (delta 23), reused 50 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (63/63), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTwDPaCspv4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from CharacterLevelLM.Datasets.CharDataset import CharDataset, CustomCollate\n",
        "from CharacterLevelLM.Models.LSTMBased import LSTMModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NH6gRUQxWLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_train = CharDataset('./CharacterLevelLM/data.txt', 100, train_size=0.95)\n",
        "dataset_test = CharDataset('./CharacterLevelLM/data.txt', 100, is_train=False, train_size=0.95)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjclcCR62ZPP",
        "colab_type": "code",
        "outputId": "955c38ff-eb1f-47cc-ac3a-edfe5565c71d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataset_test.get_vocab_size()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TawswZkS267P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTMModel(dataset_train.get_vocab_size(), 128, dataset_test.get_vocab_size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-38Zk86d43bB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "loader_train = DataLoader(dataset_train, batch_size=50, shuffle=True, collate_fn=CustomCollate())\n",
        "loader_test = DataLoader(dataset_test, batch_size=50, shuffle=True, collate_fn=CustomCollate())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq-JVRB4PFMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam\n",
        "optimizer = Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7ROoenRPTX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "criterion = nn.CrossEntropyLoss(reduction = 'none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf6KB7caPeJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "best_loss = np.inf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk5LcybRQAJi",
        "colab_type": "code",
        "outputId": "7033a5ec-5b06-4c29-ca65-22da644134b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "model = model.cuda()\n",
        "for i in range(50):\n",
        "  model.train()\n",
        "  for data in loader_train:\n",
        "    optimizer.zero_grad()\n",
        "    X, Y, mask = data\n",
        "    X, Y, mask = X.cuda(), Y.cuda(), mask.cuda()\n",
        "    \n",
        "    Y = Y.view(Y.shape[0] * Y.shape[1])\n",
        "    mask = mask.view(mask.shape[0] * mask.shape[1])\n",
        "\n",
        "    loss = (criterion(model(X), Y) * mask).mean()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = 0 \n",
        "  with torch.no_grad():\n",
        "    for idx, data in enumerate(loader_test):\n",
        "      X, Y, mask = data\n",
        "      X, Y, mask = X.cuda(), Y.cuda(), mask.cuda()\n",
        "\n",
        "      Y = Y.view(Y.shape[0] * Y.shape[1])\n",
        "      mask = mask.view(mask.shape[0] * mask.shape[1])\n",
        "\n",
        "      test_loss *= idx\n",
        "      test_loss += (criterion(model(X), Y) * mask).mean().item()\n",
        "      test_loss /= (idx + 1)\n",
        "  print(test_loss)\n",
        "  if test_loss < best_loss:\n",
        "    best_loss = test_loss\n",
        "    torch.save({'state_dict': model.state_dict()}, base_dir + '/model.pth')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8043779134750366\n",
            "1.8018550872802734\n",
            "1.8042256832122803\n",
            "1.8023762702941895\n",
            "1.8022997379302979\n",
            "1.8033647537231445\n",
            "1.7983475923538208\n",
            "1.807036280632019\n",
            "1.8050304651260376\n",
            "1.8080040216445923\n",
            "1.8046661615371704\n",
            "1.803824543952942\n",
            "1.8044979572296143\n",
            "1.8033077716827393\n",
            "1.8052600622177124\n",
            "1.8099831342697144\n",
            "1.8024168014526367\n",
            "1.8137800693511963\n",
            "1.804850697517395\n",
            "1.8075615167617798\n",
            "1.8101682662963867\n",
            "1.807334303855896\n",
            "1.8141589164733887\n",
            "1.8126269578933716\n",
            "1.815405011177063\n",
            "1.8095300197601318\n",
            "1.811915636062622\n",
            "1.814003825187683\n",
            "1.8111811876296997\n",
            "1.807555079460144\n",
            "1.815881609916687\n",
            "1.816457748413086\n",
            "1.8121964931488037\n",
            "1.8194541931152344\n",
            "1.82039213180542\n",
            "1.8167394399642944\n",
            "1.8190885782241821\n",
            "1.8128448724746704\n",
            "1.8262298107147217\n",
            "1.8197487592697144\n",
            "1.814258098602295\n",
            "1.821378469467163\n",
            "1.8186347484588623\n",
            "1.819235920906067\n",
            "1.8267265558242798\n",
            "1.8306869268417358\n",
            "1.8294165134429932\n",
            "1.8248339891433716\n",
            "1.8255943059921265\n",
            "1.8325155973434448\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIkniA7UP9MW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}